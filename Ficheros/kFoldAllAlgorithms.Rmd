---
editor_options:
  markdown:
    wrap: 72
output: pdf_document
---

```{r}
library(foreach)
library(doParallel)
library(DataExplorer)
library(dplyr)
library(pROC)
library(caret)
```

First of all we obtain the needed data and do the preprocessing to the
necessary elements as well as set up the output variable.

```{r}
data <- read.csv("../../data_tfg.csv", nrows =1800)
ind.cualit <- c(which(names(data) == "SITUACION"),which(names(data)=="SEXO"),which(names(data)=="DM"):which(names(data)=="DC"))

for(i in ind.cualit){
  
  data[,i] <- as.factor(data[, i])
  
}


OUTPUT_VAR = "SITUACION"
```

We look at imbalanced data in a table

```{r}
barplot(prop.table(table(data[[OUTPUT_VAR]])),
        col = rainbow(2),
        ylim = c(0, 1.01),
        main = "Class Distribution")
```

And the number of elements per class

```{r}

output_lev <- levels(data[[OUTPUT_VAR]])

lev_nrow <- c(nrow(data[data[[OUTPUT_VAR]] == output_lev[1],]), nrow(data[data[[OUTPUT_VAR]] == output_lev[2],]))

if (lev_nrow[1] < lev_nrow[2]){
  OUTPUT_MIN = output_lev[1]
  OUTPUT_MAJ = output_lev[2]
  nmin = lev_nrow[1]
  nmax = lev_nrow[2]
}else{
  OUTPUT_MIN = output_lev[2]
  OUTPUT_MAJ = output_lev[1]
  nmin = lev_nrow[2]
  nmaj = lev_nrow[1]
}
print(sprintf("%s : %d", OUTPUT_MIN, nmin))
print(sprintf("%s : %d", OUTPUT_MAJ, nmaj))

```

We define the metrics to be measured, amongst which the kappa factor is
a significant value to measure imbalanced data and will be the
differential measure during the training.

```{r}
metrics <- function(data, lev = levels(as.factor(data$obs)), model = NULL){
  
  met <- c(
    ACCURACY = MLmetrics::Accuracy(data[, "pred"], data[, "obs"]),
    SENS = sensitivity(data[, "pred"],data[, "obs"],positive=OUTPUT_MIN,negative=OUTPUT_MAJ),
    SPEC = specificity(data[, "pred"], data[, "obs"],positive=OUTPUT_MIN,negative=OUTPUT_MAJ),
    PPV = posPredValue(data[, "pred"], data[, "obs"],positive=OUTPUT_MIN,negative=OUTPUT_MAJ),
    NPV = negPredValue(data[, "pred"], data[, "obs"],positive=OUTPUT_MIN,negative=OUTPUT_MAJ),
    KAPPA = psych::cohen.kappa(cbind(data[, "obs"],data[, "pred"]))$kappa,
    BAL_ACC = (sensitivity(data[, "pred"],data[, "obs"],positive=OUTPUT_MIN,negative=OUTPUT_MAJ) + specificity(data[, "pred"], data[, "obs"],positive=OUTPUT_MIN,negative=OUTPUT_MAJ))/2
  )

  
  return(met)
}
```

Let us remember the different parameters of our model:

-   np: Elements of the minoritary class in each partition
-   p: Number of partitions to be made
-   b: Maximum number of models in each ensemble of each partition
-   mt: Function which returns how many trials we must make in the
    greedy sequencial approach

In order to stablish these parameters we will create a function for each
one of them:

First of all the one related to the "np" parameter which in our case
will be reduced to a function which gets the 75% of the minoritary
class.

```{r}
calculate_np <- function( nmin, nmaj,  elbow_prob=0.75) 
{
  np <- round(nmin*elbow_prob)
  return(np)
}

```

Now we move on to the number of partitions which, in our case, is
obtained using the formula studied in the original work, based on
applying the logarithmic division of values less than 1 (both negative)
to obtain a ratio between the established alpha and the number of
elements chosen per partition.

```{r}
calculate_p <- function( np, prob_codo=0.75, alpha_p= .01) 
{
  p <- ceiling(log(alpha_p)/(log(1-1/np)*np))
  return(p)
}

```

Subsequently, we approach the parameter b, which is responsible for
determining how many models at most there will be in each ensemble of
each partition made. To do this, we will take a similar approach to that
of the number of partitions, except that we will use a relationship
between nmin and np, and not just the number of minority elements per
partition (p). This way, b is always above the number of partitions
made.

```{r}

  
calculate_b <- function(np, nmin, nmaj, elbow_prob=0.75, alpha_b= .01) 
{

  b <- ceiling(log(alpha_b)/(log(1-1/nmin)*np))
  return(b)
}



```

And lastly, we will define the "mt" function, which calculates how many
tries at most should be made in order to enlarge each model ensemble in
the sequencial approach. It can be shown that the "mt" number of tries
will always be smaller than the "b" which are the maximum models for
each ensemble.

```{r}



mt <- function(b, n) { ceiling((b-n) / 3) }


```

This is an auxiliary function that just returns a continuous apply of a
given configuration "b" times. Useful for multiple seed algorithm
trainings (i.e five GBM models)

```{r}
get_function_vector <- function(b,function_training){
  function_vector <- c() 
  for(i in 1:b){
    function_vector <- append(function_vector, function_training) 
  } 
  

  return(function_vector)
}

```

Now let us set up some seed algorithms for the model. This function list
will be made by four well known ones:

-   Ranger
-   Logistic regression
-   SVM
-   GBM

The idea is to train them in different approaches and see which IPIP
variant works better, so we will make a k-fold of each of the next
approaches and see which of them seem to be a better idea.

-   Each seed algorithm alone (without IPIP)
-   Sequential IPIP with many instances of the same seed algorithm
-   Exhaustive IPIP with different seed algorithms (one of each at
    least)
-   Exhaustive IPIP but only the best ensemble

```{r}
seed_algorithms <- c(

#RFOREST
 function(df.train, metrics, OUTPUT) {

    
    tC <- trainControl(
      summaryFunction = metrics,
      allowParallel = TRUE,
      classProbs = TRUE
    )
    
    
    method <- "ranger"
    metric <- "KAPPA"
    maximize <- T
    
    cl <- makeCluster(detectCores()-2)
    clusterExport(cl, c("OUTPUT_MIN", "OUTPUT_MAJ"))
    registerDoParallel(cl)
    
    
    rf <- train(
      as.formula(sprintf("%s ~.", OUTPUT)),
      data = df.train,
      method = method,
      metric = metric,
      maximize = maximize,
      importance = "impurity",
      trControl = tC
    )
    
    stopCluster(cl)
    
    return(rf)
  },
#RLOG
 function(df.train, metrics, OUTPUT) {


    tC <- trainControl(
      summaryFunction = metrics,
      allowParallel = TRUE,
      classProbs = TRUE
    )
    
    method <- "glmnet"
    metric <- "KAPPA"
    maximize <- T
    
    cl <- makeCluster(detectCores()-2)
    clusterExport(cl, c("OUTPUT_MIN", "OUTPUT_MAJ"))
    registerDoParallel(cl)
    
    
    rlog <- train(as.formula(sprintf("%s ~.", OUTPUT)),
      data = df.train,
      method = "glmnet",
      family = 'binomial',
      metric = "KAPPA",
      maximize = T,
      trControl = tC
    )
    
        
    stopCluster(cl)
    
    
    return(rlog)
  },
#SVM
function(df.train, metrics, OUTPUT) {

    tC <- trainControl(
      summaryFunction = metrics,
      allowParallel = TRUE,
      classProbs = TRUE
    )
    
    method <- "svmLinear"
    metric <- "KAPPA"
    maximize <- T

    
        
    cl <- makeCluster(detectCores()-2)
    clusterExport(cl, c("OUTPUT_MIN", "OUTPUT_MAJ"))
    registerDoParallel(cl)
    
    
    svm <- train(
      as.formula(sprintf("%s ~.", OUTPUT)),
      data = df.train,
      method = method,
      metric = metric,
      maximize = maximize,
      trControl = tC
    )
    
      stopCluster(cl)
    
    return(svm)
  },
#GBM
 function(df.train, metrics, OUTPUT) {

    tC <- trainControl(
      summaryFunction = metrics,
      allowParallel = TRUE,
      classProbs = TRUE,
      verboseIter = FALSE
      
    )
    
    method <- "gbm"
    metric <- "KAPPA"
    maximize <- T
    
        
    cl <- makeCluster(detectCores()-2)
    clusterExport(cl, c("OUTPUT_MIN", "OUTPUT_MAJ"))
    registerDoParallel(cl)
    
    gbm <- train(as.formula(sprintf("%s ~.", OUTPUT)),
                 data = df.train,
                 method = method,
                 metric = metric,
                 maximize = maximize,
                 verbose = FALSE,
                 trControl = tC
    )
    
    stopCluster(cl)
    
    return(gbm)
  })


```

Now that we have the configurations, we proceed to obtain a separation
into balanced subsets. To do this, I obtain a series of folds with the
created function 'imbalancedFold' that allow applying that division so
that each subset of the k-fold has the imbalanced subsets distributed

```{r}
imbalancedFold <- function(data, n_folds, target, minority_class) {
  n_samples <- nrow(data)
  n_majority_total <- n_samples - sum(data[[target]] == minority_class)
  n_minority_total <- sum(data[[target]] == minority_class)
  
  n_minority_per_fold <- ceiling(n_minority_total / n_folds)
  n_majority_per_fold <- ceiling(n_samples / n_folds - n_minority_per_fold)

  fold_indices <- list()
  
  for (i in 1:n_folds) {
    
    #We choose the samples of the majoritary class
    majority_indices <- which(data[[target]] != minority_class)
    used_majority_indices <- unlist(fold_indices)
    available_majority_indices <- setdiff(majority_indices, used_majority_indices)
    
    n_available_majority <- length(available_majority_indices)
    n_majority_this_fold <- min(n_majority_per_fold, n_available_majority)
    selected_majority_indices <- sample(available_majority_indices, size = n_majority_this_fold)
    
    #We take the samples of the minoritary class
    
    minority_indices <- which(data[[target]] == minority_class)
    used_minority_indices <- setdiff(used_majority_indices, available_majority_indices)
    available_minority_indices <- setdiff(minority_indices, used_minority_indices)
    n_available_minority <- length(available_minority_indices)
    n_minority_this_fold <- min(n_minority_per_fold, n_available_minority)
    selected_minority_indices <- sample(available_minority_indices, size = n_minority_this_fold)
    
    #We collect and combine both indexes
    selected_indices <- c(selected_majority_indices, selected_minority_indices)

    fold_indices[[i]] <- selected_indices
  }
  
  return(fold_indices)
}

```

In this case we will make a k-fold of k=5

```{r}

folds <-imbalancedFold(data, 2,OUTPUT_VAR, OUTPUT_MIN)

```

Ahora definimos la funcion que realiza el entrenamiento. Sigue las ideas
explicadas en el trabajo. Consiste en realizar p particiones donde
aseguremos en cada una una cantidad np de elementos de la clase
minoritaria y sobre ellos entrenar multiples modelos.

Para eso tenemos una lista llamada dfs que contiene los indices de cada
particion bien balanceada. Sobre cada una de estas particiones
realizaremos un entrenamiento iterativo:

-   Primero se entrena el modelo sobre la primera funcion del vector de
    funciones y se almacenan sus resultados de las metrics pasadas
-   Despues se intenta ampliar el modelo hasta que la funcion de
    intentos "mt" lo limite. Para ampliar el modelo se entrena con la
    siguiente funcion de entrenamiento dada por el parametro de
    funciones y se compara el valor obtenido con esa funcion nueva y sin
    ella. Si se mejora se incorpora al ensemble, sino se pasa a un nuevo
    intento.
-   Una vez se ha terminado el numero de intentos para el ensemble
    actual se considera completado y se incorpora como modelo final dado
    para la particion.

Asi seguiremos hasta realizar este proceso en las p particiones y
tendremos el modelo como respuesta.

```{r}
train_IPIP <- function( prop.maj, OUTPUT, min_str, maj_str, train.set, test.set, 
                        configuration, prediction, metrics, b, np,  p, mt, seed=42){
  

  set.seed(seed)
  nmin = sum(train.set[[OUTPUT]] == min_str)
  nmaj = sum(train.set[[OUTPUT]] == maj_str)
  
  

  majSubSize <-  round(np*prop.maj/(1-prop.maj))
  minSubSize <-  np

  #Incluye en cada posicion los valores de los elementos de dicha particion, de 1 a p
  dfs <- list()
  
  minoritary =minoritary <- subset(train.set, train.set[[OUTPUT]] == min_str)
  majoritary = majoritary <- subset(train.set, train.set[[OUTPUT]] == maj_str)
  for(k in 1:p){
    id.minoritary <- sample(x = 1:nmin, size = minSubSize) #Index for minoritary class for each subset
    id.majoritary <- sample(x= 1:nmaj, size = majSubSize) #Indexes for majoritary class for each subset
    
    dfs[[k]] <- rbind(minoritary[id.minoritary,],majoritary[id.majoritary,])
  }
  
  E <- list() #Final model (ensemble of ensembles)


  for(k in 1:p){
    Ek <- list() # k-esim ensemble
    i <- 0 #Counter for number of tries of enlarging the ensemble
  
    #Balanced partition
    
    df <- dfs[[k]]
    model_i = 1
    while(length(Ek)<=b && i<mt(b,length(Ek))){
      #We select the elements for the training
      
      majoritary <- which(df[[OUTPUT]] == maj_str)
      minoritary <- which(df[[OUTPUT]] == min_str)
      ind.train <- c(
        sample(majoritary, size = majSubSize, replace = TRUE),
        sample(minoritary, size = minSubSize, replace = TRUE) 
      )
    
      #We train with the models in configuration with a sequential approach
      
      model <- configuration[[length(Ek)+1]](df[ind.train,], metrics, OUTPUT)
      metrics.ensemble <-
        if (length(Ek)==0){
          u <- -Inf;
          names(u) <- "KAPPA";
          u;
        } else{
          metrics(data.frame(
          obs = test.set[[OUTPUT]],
          pred = as.factor(prediction(Ek, test.set[colnames(test.set)!=OUTPUT]))
          ))
        }
      
      Ek[[length(Ek)+1]] <- model
      metrics.ensemble.new <- metrics(data.frame(
      obs = test.set[[OUTPUT]],
      pred= as.factor(prediction(Ek, test.set[colnames(test.set)!=OUTPUT]))
      ))
      
      #We check if the new model changes the result. If it does not we start trying again
      if(metrics.ensemble.new["KAPPA"] <= metrics.ensemble["KAPPA"]){ 
        i <- i+1
        Ek[[length(Ek)]] <- NULL
      } else{ 
        #If the ensemble tries to enlarge again, we restart the enlarging posibilities.
        i <- 0
      }
    } # End of the k-esim ensemble building

    E[[length(E)+1]] <- Ek
  
  }
return(E);
}


```

Now we have another possible approach of IPIP based on an exhaustive
approach of the models.

```{r}
powerset = function(s){
    len = length(s)
    l = vector(mode="list",length=2^len-1)
    counter = 1L
    for(x in 1L:length(s)){
        for(subset in 1L:counter){
            l[[counter]] = c(l[[subset]],s[x])
            counter=counter+1L
        }
    }
    return(l)
}


train_IPIP_exhaustive <- function( prop.maj, OUTPUT, min_str, maj_str, train.set, test.set, configuration, prediction, metrics, np,  p, seed=42){
  

  
  #Set random seed
  set.seed(seed)
  
  
  nmin = sum(train.set[[OUTPUT]] == min_str)
  nmaj = sum(train.set[[OUTPUT]] == maj_str)
  
  
  
  majSubSize <-  round(np*prop.maj/(1-prop.maj))
  minSubSize <-  np

  #Incluye en cada posicion los valores de los elementos de dicha particion, de 1 a p
  dfs <- list()
  
  minoritary <- subset(train.set, train.set[[OUTPUT]] == min_str)
  majoritary <- subset(train.set, train.set[[OUTPUT]] == maj_str)
  for(k in 1:p){
    id.minoritary <- sample(x = 1:nmin, size = minSubSize) #Index for minoritary class for each subset
    id.majoritary <- sample(x= 1:nmaj, size = majSubSize) #Indexes for majoritary class for each subset
    
    dfs[[k]] <- rbind(minoritary[id.minoritary,],majoritary[id.majoritary,])
  }
  
  E <- list() #Final model (ensemble of ensembles)


  for(k in 1:p){
    Ek <- list() # k-esim ensemble

  
    #Balanced partition

    df <- dfs[[k]]
    majoritary <- which(df[[OUTPUT]] == maj_str)
    minoritary <- which(df[[OUTPUT]] == min_str)
    
      ind.train <- c(
        sample(majoritary, size = majSubSize, replace = TRUE),
        sample(minoritary, size = minSubSize, replace = TRUE) 
      )

      Ek <- list()
      for(conf in 1:length(configuration)){
        Ek[[length(Ek)+1]] <- configuration[[conf]](df[ind.train,], metrics, OUTPUT)
      }

      all_sets <- powerset(Ek)
      max_kappa <- function(model){
          metrics(data.frame(
              obs = test.set[[OUTPUT]],
              pred = as.factor(prediction(model, as.data.frame(test.set[, -which(names(test.set) == OUTPUT)])))
          ))["KAPPA"]
      }

      
      max_set <- all_sets[[which.max(lapply(all_sets, function(s) max_kappa(s)))]]
     # End of the k-esim ensemble building

    E[[length(E)+1]] <- max_set
  
  }
return(E);
}


```

Now the prediction function is missing. In our case it consists of two
functions.

The first one is applied to the ensemble of models of a specific
partition. On each established model, the specific prediction (predict
method of the same) is made. Then a table is made that assigns to each
example the proportion of models that have predicted in that way. If
more than q (75% by default, that is, at least three-quarters of the
models predict that it is cured) have been predicted, it is established
that it is predicted as OUTPUT_MAJ and if not, it will be deceased.

Finally, the same thing is done but instead of using the predict
function of each model, the given prediction function on each ensemble
is used, the proportion is made on the ensemble sets and if the
prediction proportion value is \>50%, it is assumed as OUTPUT_MAJ being
if not OUTPUT_MIN.

```{r}
prediction <- function(conj.model, x, q = 0.75){ #q=0.75, pero se deberían probar valores como 0.5, 0.25, 0.75...
  pred <- data.frame(matrix(nrow=nrow(x),ncol=0))
  for(model in conj.model) pred <- cbind(pred, predict(model,x))
  pred <- apply(pred, 1, function(x) prop.table(table(x))[OUTPUT_MAJ])
  ifelse(is.na(pred) | pred<q, OUTPUT_MIN, OUTPUT_MAJ)
}

prediction.final <- function(ensemble, x, q = 0.5){
  # Colocamos en cada fila de un conjunto de data todas las predictiones para una muestra
  pred <- as.data.frame(lapply(ensemble, function(e) prediction(e,x)))
  pred <- apply(pred, 1, function(x) prop.table(table(x))[OUTPUT_MAJ])
  ifelse(is.na(pred) | pred<q, OUTPUT_MIN, OUTPUT_MAJ)
}

```

Ahora pasamos a realizar el entrenamiento sobre cada configuracion
establecida en la lista de configuraciones. Para ello recorremos en cada
configuracion el k-fold y damos para cada fold una funcion de vectores
asociada al numero b de modelos maximos para un ensemble (de momento
todas las funciones son iguales en cada iteracion, pero este approach
permite crear vectores de funciones variables).

```{r warning=TRUE}
mean_metrics.IPIPrepeated <- list()
mean_metrics.seed <- list()
mean_metrics.IPIPexhaustRepeat <- list()



for(alg in 1:length(seed_algorithms)){
  
print(sprintf("Seed algorithm: %d", alg))
  
  metrics.final.IPIPrepeated <- list()
  metrics.final.IPIPexhaustRepeat <- list()
  metrics.final.seed <- list()
  
  for (i in 1:length(folds)) {
    
    train.set <- data[unlist(folds[i]),]
    test.set <- data[-unlist(folds[i]),]
    
    nmin = sum(train.set[[OUTPUT_VAR]] == OUTPUT_MIN)
    nmaj = sum(train.set[[OUTPUT_VAR]] == OUTPUT_MAJ)
    
    np <- calculate_np( nmin, nmaj)
    p <- calculate_p(np)
    b <- calculate_b(np, nmin, nmaj)
    
    print("Training exhaustive IPIP for seed algorithm group")
    
    conf<- get_function_vector(b, seed_algorithms[alg])
    ensemble.fold <- train_IPIP_exhaustive(0.55, OUTPUT_VAR, OUTPUT_MIN, OUTPUT_MAJ, train.set, test.set, conf, prediction,  metrics,np, p)
    
    print(sprintf("Ensembles length in exhaustive fold: %d", i))
    print(unlist(lapply(ensemble.fold,length)))
    
    metrics.final.IPIPexhaustRepeat <- append( metrics.final.IPIPexhaustRepeat, 
      metrics(data.frame(
      obs = test.set[[OUTPUT_VAR]],
      pred= as.factor(prediction.final(ensemble.fold, 
                                       test.set[,names(test.set) != OUTPUT_VAR]))
      )))
    
    
    
    print("Training sequential IPIP for seed algorithm group")
    
    conf<- get_function_vector(b, seed_algorithms[alg])
    ensemble.fold <- train_IPIP(0.55, OUTPUT_VAR, OUTPUT_MIN, OUTPUT_MAJ, train.set, test.set, conf, prediction,  metrics, b, np, p, mt)
    
    print(sprintf("Ensembles length in sequential in fold: %d", i))
    print(unlist(lapply(ensemble.fold,length)))
    
    metrics.final.IPIPrepeated <- append( metrics.final.IPIPrepeated, 
      metrics(data.frame(
      obs = test.set[[OUTPUT_VAR]],
      pred= as.factor(prediction.final(ensemble.fold, 
                                       test.set[,names(test.set) != OUTPUT_VAR]))
      )))
    
    
       print("Now training the seed algorithm")
    
    model_seed <- seed_algorithms[[alg]](train.set, metrics, OUTPUT_VAR)
    
    metrics.final.seed <- append( metrics.final.seed, metrics(data.frame(
      obs = test.set[[OUTPUT_VAR]],
      pred = predict(model_seed,test.set)
    )))
    


  
  }
  
  mean_metrics.IPIPrepeated <- append(mean_metrics.IPIPrepeated, apply(matrix(unlist(metrics.final.IPIPrepeated), ncol= 7, byrow=T), 2, mean))
  
    mean_metrics.IPIPexhaustRepeat <- append(mean_metrics.IPIPexhaustRepeat, apply(matrix(unlist(metrics.final.IPIPexhaustRepeat), ncol= 7, byrow=T), 2, mean))
  
  
    mean_metrics.seed <- append(mean_metrics.seed, apply(matrix(unlist(metrics.final.seed), ncol= 7, byrow=T), 2, mean))
  
  
}


```

Finalmente se muestra el resultado de las diferentes estadisticas para
cada configuracion dada.

```{r}

matrix_mean.seed <- matrix(mean_metrics.seed, nrow = 4, ncol = 7, byrow = TRUE)
matrix_mean.IPIPrepeated <- matrix(mean_metrics.IPIPrepeated, nrow = 4, ncol = 7, byrow = TRUE)
matrix_mean.IPIPexhaustRepeat <- matrix(mean_metrics.IPIPexhaustRepeat, nrow = 4, ncol = 7, byrow = TRUE)


col_names <- c("ACCURACY", "SENS", "SPEC", "PPV", "NPV", "KAPPA", "BAL_ACC")
row_names <- c("RANGER", "RLOG", "SVM", "GBM")

colnames(matrix_mean.seed) <- col_names
rownames(matrix_mean.seed) <- row_names

colnames(matrix_mean.IPIPrepeated) <- col_names
rownames(matrix_mean.IPIPrepeated) <- row_names

colnames(matrix_mean.IPIPexhaustRepeat) <- col_names
rownames(matrix_mean.IPIPexhaustRepeat) <- row_names

print("IPIP SEQUENTIAL REPEAT")
print(matrix_mean.IPIPrepeated)

print("IPIP EXHAUST REPEATED")
print(matrix_mean.IPIPexhaustRepeat)

print("SEED ALGORITHM")
print(matrix_mean.seed)
```
