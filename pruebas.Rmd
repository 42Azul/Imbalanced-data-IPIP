
Pillamos los datos


```{r}
library(doParallel)
library(DataExplorer)
library(dplyr)
library(pROC)
library(caret)

```

```{r}
data <- read.csv("../adult.csv")
data <- data %>% select(-c(education))
#train.set <- read.csv("~/Alejandro/train_Alejandro.csv")
#test.set <- read.csv("~/Alejandro/test_Alejandro.csv")
#str(train.set)

#Preproceso expres
data$income[data$income == '>50K'] <-  'rico'
data$income[data$income == '<=50K'] <-  'pobre'


str(data)
```

Vemos como estan los datos MUY desbalanceados

```{r}
barplot(prop.table(table(data$income)),
        col = rainbow(2),
        ylim = c(0, 1.01),
        main = "Class Distribution")
```


Vemos cuanto hay de cada tipo

```{r}
nrow(data[data$income == 'pobre',])
nrow(data[data$income == 'rico',])
```

Hacemos un split de entrenamiento y test. ¿Como hago split, así normal?

```{r}
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.7,0.3))
data.train  <- data[sample, ]
data.test   <- data[!sample, ]

nrow(data.train)
nrow(data.test)
```

Vemos cuanto hay de cada tipo en train

```{r}
nrow(data.train[data.train$income == 'pobre',])
nrow(data.train[data.train$income == 'rico',])

barplot(prop.table(table(data.train$income)),
        col = rainbow(2),
        ylim = c(0, 1.01),
        main = "Class Distribution Train")
```

Vemos cuanto hay de cada tipo en test

```{r}
barplot(prop.table(table(data.test$income)),
        col = rainbow(2),
        ylim = c(0, 1.01),
        main = "Class Distribution Test")
        
nrow(data.test[data.test$income == 'pobre',])
nrow(data.test[data.test$income == 'rico',])
```


Cambiamos a factores los necesarios
```{r}


# Deberíamos también tratar 

ind.cualit <- c(which(names(data.train) == "workclass"),which(names(data.train)=="education"), which(names(data.train)=="marital.status"):which(names(data.train)=="gender"), which(names(data.train)=="native.country"):which(names(data.train)=="income"))



for(i in ind.cualit){
  
  data.train[,i] <- as.factor(data.train[, i])
  data.test[,i] <- as.factor(data.test[, i])
  
}

str(data.train)
```



Aplicamos p-subsets


```{r}



ricos <- data.train %>% dplyr::filter(income == "rico")
nrow(ricos)


pobres <- data.train %>% filter(income == "pobre")
nmin <- nrow(ricos)
alpha <- .01
```

Nos sale que hay 8116 pobres

```{r}
curve(log(alpha)/(log(1-1/nmin)*np), from = 500, to = 5000, xname = "np", ylab = "p")
grid()

np <- ceiling(nmin*0.75)
np
```
Queremos el 75%

```{r}

p <- log(alpha)/(log(1-1/nmin)*np)
p
```

Tendremos que coger 7 modelos.

```{r}
prop.mayoritaria<-0.55
set.seed(42)
p <- ceiling(p)
dfs <- list()
# Seleccionamos todos los  pobres que usaremos, y los reordenamos

for(k in 1:p){
  id.ricos <- sample(x = 1:nrow(ricos), size = np) #Índices de clase minoritaria para cada subconjunto
  id.pobres <- sample(x= 1:nrow(pobres), size = round(np*prop.mayoritaria/(1-prop.mayoritaria))) #Índices de la clase mayoritaria para cada subconjunto
  
  dfs[[k]] <- rbind(ricos[id.ricos,],pobres[id.pobres,])
}
```

Ver cuantos vectores distintos hay y su dimensión (número de features)

```{r}
unique(unlist(lapply(dfs,dim)))
```
```{r}
unique(lapply(dfs,function(x) prop.table(table(x$income))))
```
Las métricas, especialmente KAPPA (igual ROC después)

```{r}
metricas <- function(data, lev = levels(as.factor(data$obs)), model = NULL){
  c(
    ACCURACY = MLmetrics::Accuracy(data[, "pred"], data[, "obs"]),
    SENS = sensitivity(data[, "pred"],data[, "obs"],positive="rico",negative="pobre"),
    SPEC = specificity(data[, "pred"], data[, "obs"],positive="rico",negative="pobre"),
    PPV = posPredValue(data[, "pred"], data[, "obs"],positive="rico",negative="pobre"),
    NPV = negPredValue(data[, "pred"], data[, "obs"],positive="rico",negative="pobre"),
    KAPPA = psych::cohen.kappa(cbind(data[, "obs"],data[, "pred"]))$kappa,
    BAL_ACC = (sensitivity(data[, "pred"],data[, "obs"],positive="rico",negative="pobre") + specificity(data[, "pred"], data[, "obs"],positive="rico",negative="pobre"))/2
  )
}
```

Ahora tomamos los hiperparámetros y hacemos el entrenamiento en random forest:

```{r}
hiperparametros <- expand.grid(
  mtry = 0:6*3+1,
  min.node.size = 1:3*10-9,
  splitrule = "gini"
)
hiperparametros
```

Siendo la función de predicción del modelo para cada modelo de cada subproblema
```{r}
prediccion <- function(ensemble, x, q = 0.75){
  print(34)
  pred <- data.frame(matrix(nrow=nrow(x),ncol=0))
  for(modelo in ensemble) pred <- cbind(pred, predict(modelo,x))
  pred <- apply(pred, 1, function(x) prop.table(table(x))["pobre"])
  ifelse(is.na(pred) | pred<q, "rico", "pobre")
}
```

Nos falta el valor de b que es el número de modelos que habrá en cada conjunto. Para eso usamos formula similar a la superior:

```{r}
alpha_b <- 0.01
b <- ceiling(log(alpha_b)/(log(1-1/np)*np))
b

```
Ahora calculamos una manera de ver 'mt', que es las veces que el algoritmo se puede equivocar o no aportar suficiente en un problema dado. Como conforme el cardinal de E sea mayor, menos probable es que el modelo aporte, así que vamos a hacerlo inversamente proporcional al mismo. (b siempre es mayor que n)

```{r}
mt <- function(n) { ceiling((b-n) / 3) }
plot(0:b, mt(0:b), xlab = "|E|", ylab = "mt")
grid()
```
Procedemos directamente a entrenar cada subproblema con sus modelos:


```{r}
E <- list() # Modelo final (ensemble de ensembles)
set.seed(37)

tC <- trainControl(
  summaryFunction = metricas,
  method = "cv",
  number = b,
  allowParallel = TRUE,
  classProbs = TRUE
)
for(k in 1:p){
  Ek <- list() # Ensemble de modelos k-ésimo
  i <- 0 # Contador para el número de intentos de ampliar el ensemble
  # Conjunto de datos perfectamente balanceado:
  df <- dfs[[k]]
  while(length(Ek)<=b && i<mt(length(Ek))){
    # Seleccionamos muestras para entrenar el modelo de random forest
    pob <- which(df$income == "pobre")
    ricos <- which(df$income == "rico")
    
    ind.train <- c(
      sample(pob, size = round(np*prop.mayoritaria/(1-prop.mayoritaria)), replace = TRUE),
      sample(ricos, size = np, replace = TRUE)
    )
    
    cl <- makeCluster(detectCores()-2)
    registerDoParallel(cl)
    
    rf <- train(
      x = df[ind.train,-1],
      num.trees = 200,
      importance = "impurity",
      y = df$income[ind.train],
      method = "ranger",
      metric = "KAPPA",
      maximize = T,
      trControl = tC,
      tuneGrid = hiperparametros
    )
    
    stopCluster(cl)
    
    # Evaluamos el ensemble actual (sin el nuevo modelo)
    
    metricas.ensemble <-
      if (length(Ek)==0){
        u <- -Inf
        names(u) <- "KAPPA"
        u
      } else metricas(data.frame(
              obs = data.test$income,
              pred= prediccion(Ek, data.test[-1])
           ))
    
    Ek[[length(Ek)+1]] <- rf
    # Evaluamos el ensemble formado al añadir el nuevo modelo
    metricas.ensemble.2 <- metricas(data.frame(
      obs = data.test$income,
      pred= prediccion(Ek, data.test[-1])
    ))
    # Comparamos las metricas
    if(metricas.ensemble.2["KAPPA"] <= metricas.ensemble["KAPPA"]){ # Si el ensemble no mejora con el nuevo modelo...
      i <- i+1
      Ek[[length(Ek)]] <- NULL
    } else{ # En caso de ampliar el ensemble, reseteamos las oportunidades de cara a una nueva ampliación
      i <- 0
    }
    
  } # Fin del WHILE (hemos terminado de construir el ensemble k-ésimo)
  
  # Guardamos la información del ensemble k-ésimo
  E[[length(E)+1]] <- Ek

} # FIN. Hemos terminado de contruir el ensemble final

saveRDS(E,"./TrainCompleto.rds")
```
```{r}
ensemble <- readRDS("../TrainCompleto.rds")
```

Veamos los modelos que son

```{r}
unlist(lapply(ensemble,length))
```

Ahora hacemos el ensemble y predecimos:

```{r}
prediccion.final <- function(ensemble, x, q = 0.5){
  # Colocamos en cada fila de un conjunto de datos todas las predicciones para una muestra
    pred <- as.data.frame(lapply(ensemble, function(e) prediccion(e,x)))
  pred <- apply(pred, 1, function(x) prop.table(table(x))["pobre"])
  ifelse(is.na(pred) | pred<q, "rico", "pobre")
}
```

```{r}
metricas.final.rf<- metricas(data.frame(
    obs = data.test$income,
    pred= prediccion.final(ensemble, data.test[-1])
))
```

Vemos el resultado

```{r}
metricas.final.rf
```


